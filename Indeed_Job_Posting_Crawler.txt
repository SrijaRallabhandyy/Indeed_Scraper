# All the necessary imports
from bs4 import BeautifulSoup
import requests
import re
from datetime import datetime
import csv

# URL of indeed.com which gives information regarding New York State - Past 24hrs
URL = 'https://www.indeed.com/jobs?q=&l=New+York+State&fromage=1'
file_name='indeed.csv' #CSV file to which data needs to be stored
page = requests.get(URL)
soup = BeautifulSoup(page.content, 'html.parser')

#Code to select the location drop down to scrape job count based on location
full_location_dropdown = soup.find("ul",{"id":"filter-location-menu"}).findAll("li")
# print(full_location_dropdown[0])
location_links=[] #Href links of all the locations
location=[] #List of locations from the drop down
job_count=[]  #Total job count at each location


#Loop which takes the html structure as input and returns the necessary details mentioned above
for i in full_location_dropdown:
    loc_link_temp=(re.findall('<a href="([^"]*)"',str(i)))
    loc_link_temp_1="https://www.indeed.com"+loc_link_temp[0]
    temp=(re.findall('<span class="rbLabel">([^"]*)</span>', str(i)))
    location_temp=temp[0]
    job_count_temp=temp[1]
    job_count_temp = job_count_temp.lstrip('\xa0(')
    job_count_temp = job_count_temp.rstrip(')')
    location_links.append(loc_link_temp_1)
    location.append(location_temp)
    job_count.append(job_count_temp)

# print(location_links)
# print(location)
# print(job_count)

full_time=[] # List of full time count
part_time=[] #List of part time job counts based on location
temporary=[] #List of temporary job counts based on location
contract=[] #Contract based job count
internship=[] # Internship based job count
type=[]

count_1=[]
count=0
#Loop to run individual location based, to get the sub job counts
for i in range(0,len(location_links)):
    location_links[i] = location_links[i].replace("&amp;", "&")
    page = requests.get(location_links[i])

    print(location_links[i])
    soup = BeautifulSoup(page.content, 'html.parser')
    full_job_dropdown = soup.find("ul", {"id": "filter-job-type-menu"}).findAll("li")
    # print(full_job_dropdown)
    for k in range(0,len(full_job_dropdown)):
        temp = (re.findall('<span class="rbLabel">([^"]*)</span>', str(full_job_dropdown[k])))
        type_of_job=temp[0]
        # print(type_of_job)
        sub_job_count=temp[1]
        # print(sub_job_count)
        sub_job_count = sub_job_count.lstrip('\xa0(')
        sub_job_count = sub_job_count.rstrip(')')
        # type.append(type_of_job)
        # count_1.append(sub_job_count)
        with open(file_name, 'a', newline='') as file:
            print("Running")
            now = datetime.now()
            writer = csv.writer(file)
            row = [now.strftime("%D %H:%M:%S"),location[i],type_of_job,sub_job_count]
            writer.writerow(row)

